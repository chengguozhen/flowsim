
\section{introduction}
\label{sec:ref}

A promise of Software Defined Networking is the programmatic, rather
than manual, configuration and control control of network devices and packet 
flows, thus bringing a far greater degree of intelligence to the management and
orchestration of diverse, heterogeneous network elements within a
network. One of the key mechanisms for delivering on this promise is
the OpenFlow model, which provides a rich and powerful set of packet 
processing primitives.

% FIXME: Does this seem legit?

OpenFlow supports the ability to write programs that establish an initial
network state and then react to network events by dynamically configuring 
switching tables on network elements. These programs are hosted and executed by 
an OpenFlow controller, but the primitives of those programs are
defined in term's of a switch's data plane. For example, a program could install
rules in a wireless access point that quarantine all unauthenticated clients, 
isolates all authenticated guests, and provides multiple levels of QoS to
authenticated home clients. That program would partition traffic into classes of
service by selecting flows and providing the appropriate treatments: police,
shape, discard, deliver, etc. 
Those policies are defined by matching fields in the various protocols 
comprising each packet and taking appropriate actions such as modifying 
protocol fields, inserting or removing virtual network layers, or simply
dropping packets.

These programs, once written are deployed to network elements through the
OpenFlow protocol's state modification messages (e.g., modifying a flow
by installing new matching and processing rules). However, there are no
guarantees that the network element is capable of enacting those changes.
For example, a new processing rule may require flow tables backed by
TCAM to support efficient wildcard matches. Not all devices are equipped
with hardware capable of delivering that functionality. The problem is
partially addressed by the Open Networking Foundation (ONF's) work on
Table Type Patterns (TTPs) to specify the capabilities of network elements.
These can be used by the controller to determine if an OpenFlow program
can be executed by the network elements in the area network.

While promising, OpenFlow can be seen as inaccessible to newcomers to the 
technology. There are a number of reasons for this. First, OpenFlow is not a 
single specification. there are many different versions of the model and its 
accompanying protocol, and they have not evolved in a strictly additive way. 
Newer versions of the protocol revise, replace, and change the semantics of 
previously established ideas. Second, the OpenFlow model is defined by a set of 
abstractions with complex and interdependent behaviors, which can make it 
difficult to understand precisely how packets flow through the system.
Third, the existing tools to experiment and debug OpenFlow programs are 
largely limited in feature support, and provide limited visibility into the 
internals of the OpenFlow packet processing machine.

In this paper, we present a re-imagined model of OpenFlow for
packet processing, in a way that clearly delineates the complex web of behaviors
defined by OpenFlow. In particular, we define a switch as a parametric (highly 
configurable) pipeline with loosely coupled packet processing stages that 
correspond to the primary abstractions in OpenFlow. To support learning and 
experimentation with this model, we have implemented FlowSim, a visual debugging
tool that allows users to define their own processing pipelines and step through
various processing stages following the packet flow. To help support 
experimentation, FlowSim supports matching and modification of arbitrary 
protocol fields. By rephrasing the OpenFlow model in this way, and providing a 
visual tool that exposes the programming primitives, we have been successful
at dramatically lowering entry barrier for network developers and operators to 
write OpenFlow programs.

% OpenFlow Experimentation & Debugging
% How to make it easy?
%   What makes it hard?
% How to make it useful?
%   Why is it not useful in current state?

\textbf{Contributions.} We make the following contribution
\begin{itemize}
  \item \textbf{Parametric pipeline} --- The overall pipeline abstraction is
        highly configurable allowing configurations that model OpenFlow 
        versions 1.0, 1.1, 1.2, 1.3, 1.4, and beyond.
  \item \textbf{Definable protocols} - Protocol abstractions are defined 
        independent of the pipeline. Table match and protocol modification are
        built-in operations and synthesized for any well defined protocol.
  \item \textbf{Table types and constraints} --- Flow tables carry types and
        constraints on flow entries that prevent users from creating certain
        unsafe behaviors. The types and constraints can also be used to model
        specific vendor implementations of the OpenFlow pipeline.
  \item \textbf{Single step simulation} --- A pipeline execution can be simulated
        against a trace of input packets A single step correlates to OpenFlow
        actions.
  \item \textbf{Abstraction visualization} --- There are graphical representations
        of most of the abstractions of the system. This provides a more intuitive
        view of the system than blah.
\end{itemize}

This paper is organized as follows: \textbf{TODO: Write me! (if needed)}.
